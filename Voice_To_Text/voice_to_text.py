import webrtcvad
import collections
import pyaudio
import wave
import speech_recognition as sr

socketio = None  # s·∫Ω ƒë∆∞·ª£c g√°n t·ª´ app

def set_socket(io):
    global socketio
    socketio = io

def clean_filler_words(text):
    fillers = [
        "·ªù", "·ª´", "√†", "·ª´m", "√† ·ªù", "·ªùm", "·ªù...", "·ª´...", "√†...",
        "∆∞...", "h·ª´", "∆°", "hmm", "·ªù th√¨", "ki·ªÉu nh∆∞", "ki·ªÉu ki·ªÉu"
    ]
    words = text.lower().split()
    filtered_words = [word for word in words if word not in fillers]
    return ' '.join(filtered_words)

def record_vad(filename="my_voice.wav", timeout=10):
    vad = webrtcvad.Vad(2)
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000
    FRAME_DURATION = 30  # milliseconds
    FRAME_SIZE = int(RATE * FRAME_DURATION / 1000)
    NUM_FRAMES = int(RATE / FRAME_SIZE * timeout)

    p = pyaudio.PyAudio()
    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE,
                    input=True, frames_per_buffer=FRAME_SIZE)

    ring_buffer = collections.deque(maxlen=int(1000 / FRAME_DURATION))
    triggered = False
    voiced_frames = []

    print("üé§ Ch·ªù ph√°t hi·ªán ti·∫øng n√≥i...")
    if socketio:
        socketio.emit("start_recording", {"message": "üé§ H√£y n√≥i g√¨ ƒë√≥!"})

    for i in range(NUM_FRAMES):
        frame = stream.read(FRAME_SIZE, exception_on_overflow=False)
        is_speech = vad.is_speech(frame, RATE)

        if not triggered:
            ring_buffer.append((frame, is_speech))
            if len([f for f, speech in ring_buffer if speech]) > 0.9 * ring_buffer.maxlen:
                triggered = True
                if socketio:
                    socketio.emit("voice_detected", {"message": "üó£Ô∏è ƒêang n√≥i..."})
                voiced_frames.extend([f for f, _ in ring_buffer])
                ring_buffer.clear()
        else:
            voiced_frames.append(frame)
            ring_buffer.append((frame, is_speech))
            if len([f for f, speech in ring_buffer if not speech]) > 0.9 * ring_buffer.maxlen:
                break

    stream.stop_stream()
    stream.close()
    p.terminate()

    if socketio:
        socketio.emit("end_recording")

    if not voiced_frames:
        print("‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c ti·∫øng n√≥i.")
        return None

    wf = wave.open(filename, 'wb')
    wf.setnchannels(CHANNELS)
    wf.setsampwidth(p.get_sample_size(FORMAT))
    wf.setframerate(RATE)
    wf.writeframes(b''.join(voiced_frames))
    wf.close()

    print(f"‚úÖ ƒê√£ l∆∞u gi·ªçng n√≥i th√†nh {filename}")
    return filename

def record_and_transcribe():
    audio_path = record_vad()
    if not audio_path:
        result = {"status": "error", "message": "Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c ti·∫øng n√≥i."}
        if socketio:
            socketio.emit("result_text", result)
        return result

    recognizer = sr.Recognizer()
    with sr.AudioFile(audio_path) as source:
        audio = recognizer.record(source)

    try:
        text = recognizer.recognize_google(audio, language="vi-VN")
        cleaned_text = clean_filler_words(text)
        print(f"üëÇ N·ªôi dung ƒë√£ n√≥i: {cleaned_text}")
        result = {"status": "success", "text": cleaned_text}
    except sr.UnknownValueError:
        result = {"status": "error", "message": "Kh√¥ng hi·ªÉu b·∫°n n√≥i g√¨."}
    except sr.RequestError as e:
        result = {"status": "error", "message": f"L·ªói khi g·ª≠i y√™u c·∫ßu: {e}"}

    if socketio:
        socketio.emit("result_text", result)

    return result
